---
title: "MLHO Vanilla"
author: Hossein Estiri
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MLHO Vanilla}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# make sure the package is installed --> devtools::install_github("hestiri/mlho")
library(mlho)
```



## MLHO Vanilla implementation

Here we go through the vanilla implementation of MLHO using the synthetic data provided in the package.

The synthetic data `syntheticmass` downloaded and prepared according to MLHO input data model from [SyntheticMass](https://synthea.mitre.org/downloads), generated by [SyntheaTM](https://synthetichealth.github.io/synthea/), an open-source patient population simulation made available by [The MITRE Corporation](https://health.mitre.org/).

```{r}
data("syntheticmass")
```
here's how `dbmart` table looks (there's an extra column that is the translation of the `phenx` concepts):
```{r}
head(dbmart)
```
our demographic table contains: `r colnames(dems)`.


Install and load the required packages:
```{r}
if(!require(pacman)) install.packages("pacman")

pacman::p_load(data.table, devtools, backports, Hmisc, tidyr,dplyr,ggplot2,plyr,scales,readr,
               httr, DT, lubridate, tidyverse,reshape2,foreach,doParallel,caret,gbm,lubridate,praznik)
```


##split data into train-test
```{r}
uniqpats <- c(as.character(unique(dbmart$patient_num)))
#using a 70-30 ratio
test_ind <- sample(uniqpats,
                   round(.3*length(uniqpats)))

test_labels <- subset(labeldt,labeldt$patient_num %in% c(test_ind))
print("test set lables:")
table(test_labels$label)
train_labels <- subset(labeldt,!(labeldt$patient_num %in% c(test_ind)))
print("train set lables:")
table(train_labels$label)
# train and test sets 
dat.train  <- subset(dbmart,!(dbmart$patient_num %in% c(test_ind)))
dat.test <- subset(dbmart,dbmart$patient_num %in% c(test_ind))
```

now dimensionality reduction on training set
## MSMR lite
from here, we will split the data into a train and a test set and apply `MSMR.lite` to the training data
```{r}
data.table::setDT(dat.train)
dat.train[,row := .I]
dat.train$value.var <- 1
uniqpats.train <- c(as.character(unique(dat.train$patient_num)))

##here is the application of MSMR.lite
dat.train <- MSMSR.lite(MLHO.dat=dat.train,
                        patients = uniqpats.train,
                        sparsity=0.005, 
                        labels = labeldt,
                        topn=200)
```
Notice that we are removing concepts that had prevalence less than 0.5% and then only taking the top 200 after the JMI rankings. See help (`?mlho::MSMSR.lite`) for `MSMR.lite` parameters. 

Now we have the training data with the top 200 features, to which we can add demographic features. Now on to prepping the test set:
```{r}
dat.test <- subset(dat.test,dat.test$phenx %in% colnames(dat.train))
setDT(dat.test)
dat.test[,row := .I]
dat.test$value.var <- 1
uniqpats.test <- c(as.character(unique(dat.test$patient_num)))

dat.test <- MSMSR.lite(MLHO.dat=dat.test,patients = uniqpats.test,sparsity=NA,jmi = FALSE,labels = labeldt)
```
Here notice that we only used `MSMR.lite` to generate the wide table that matches to the `dat.train` table.


##Modeling
we will use the `mlearn` function to do the modeling, which includes training the model and testing it on the test set.
```{r}
model.test <- mlearn(dat.train,
                   dat.test,
                   dems=dems,
                   save.model=FALSE,
                   classifier="glmboost",
                   note="mlho_terst_run",
                   cv="cv",
                   nfold=5,
                   aoi="prediabetes",
                   multicore=TRUE)
```

See help (`?mlho::mlearn`) for `mlearn` parameters. 

